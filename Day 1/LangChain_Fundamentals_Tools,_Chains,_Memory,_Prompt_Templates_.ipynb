{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#LangChain Fundamentals Tools, Chains, Memory, Prompt Templates\n",
        "\n",
        "#ðŸ”§ Requirements"
      ],
      "metadata": {
        "id": "vsw_zCZTB-MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \\\n",
        "langchain==0.2.* \\\n",
        "langchain-core==0.2.* \\\n",
        "langchain-community==0.2.* \\\n",
        "langchain-google-genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg-K6u1M9DRL",
        "outputId": "6cf0197a-987a-41be-a316-3094ea1393f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.2.* in /usr/local/lib/python3.12/dist-packages (0.2.17)\n",
            "Requirement already satisfied: langchain-core==0.2.* in /usr/local/lib/python3.12/dist-packages (0.2.43)\n",
            "Requirement already satisfied: langchain-community==0.2.* in /usr/local/lib/python3.12/dist-packages (0.2.19)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (1.0.10)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-4.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.*) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.*) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.*) (3.13.2)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.*) (0.2.4)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.*) (0.1.147)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.*) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.*) (2.12.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.*) (2.32.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.*) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.2.*) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.2.*) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.2.*) (4.15.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.2.*) (0.6.7)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.53.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.55.0)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain_google_genai-2.1.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Using cached langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Using cached langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Using cached langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting google-generativeai<0.9.0,>=0.8.0 (from langchain-google-genai)\n",
            "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached langchain_google_genai-2.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached langchain_google_genai-2.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached langchain_google_genai-2.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached langchain_google_genai-2.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached langchain_google_genai-2.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Using cached langchain_google_genai-2.0.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached langchain_google_genai-2.0.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached langchain_google_genai-2.0.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.7.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.*) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.*) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.*) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.*) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.*) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.*) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.*) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.*) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.*) (0.9.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.45.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.25.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.*) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.*) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.*) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.*) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.*) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.*) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.*) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.*) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.*) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.*) (2.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.*) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.*) (3.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.72.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.*) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.*) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.*) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.*) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.3.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ”‘ 1. Setup: Gemini API & LangChain"
      ],
      "metadata": {
        "id": "LKDAgw9VCFNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD45v3dg7V5J0J0sK_pyhqzuksZlYlqhIA\"\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-flash-latest\")\n",
        "#AIzaSyDqsEze47E4A8Xlm9WbGRTDYzpwY3VIrTA"
      ],
      "metadata": {
        "id": "0esuLSiDABg0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ§© 2. Prompt Templates\n",
        "LangChain prompt templates let you define structured inputs for LLMs."
      ],
      "metadata": {
        "id": "KkmGF6GICIg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate # Import the PromptTemplate class\n",
        "\n",
        "prompt = PromptTemplate.from_template( # Create a PromptTemplate instance\n",
        "    \"You are a helpful assistant. Summarize the following article:\\n\\n{article}\" # Define the prompt template string with an 'article' input variable\n",
        ")\n",
        "\n",
        "formatted_prompt = prompt.format(article=\"OpenAI released a new version of ChatGPT.\") # Format the prompt with a specific article"
      ],
      "metadata": {
        "id": "gmhvlF9TAHyh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ”— 3. Chains\n",
        "Chains let you connect LLMs and other logic into a sequence.\n",
        "\n",
        "ðŸ§  Simple LLMChain"
      ],
      "metadata": {
        "id": "VlrUfRLpCLXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm\n",
        "\n",
        "result = chain.invoke({\"article\": \"The new GPT-4o model is optimized for multimodal tasks.\"})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C6OLYhHAM4v",
        "outputId": "3c9f46b9-de72-4608-b649-0463ab751a5c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='The new GPT-4o model is optimized for multimodal tasks.' response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-bf8db73d-46de-43ca-aefc-c16b87f03356-0' usage_metadata={'input_tokens': 27, 'output_tokens': 13, 'total_tokens': 40}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ› ï¸ 4. Tools (via custom functions)\n",
        "LangChain supports tools via Tool wrappers. Hereâ€™s a basic example:"
      ],
      "metadata": {
        "id": "QKZKTOs_COoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def get_current_year(query: str = \"\") -> int:\n",
        "    \"\"\"Returns the current year. The input query is ignored.\"\"\"\n",
        "    from datetime import datetime\n",
        "    return datetime.now().year"
      ],
      "metadata": {
        "id": "6jXG14n6AOiY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def calculate_percentage(value: float, percent: float) -> float:\n",
        "    \"\"\"Calculate percentage of a value.\"\"\"\n",
        "    return (value * percent) / 100\n"
      ],
      "metadata": {
        "id": "59iC9EJ6Y3Zc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ§  5. Memory\n",
        "Memory allows chat history or state to be remembered.\n",
        "\n"
      ],
      "metadata": {
        "id": "jiXWTYqRCSEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "print(\"Memory initialized successfully\")\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    return_messages=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDFIGNsbYCYP",
        "outputId": "60290a15-7373-4230-80c0-373413c3671f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory initialized successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Verify Memory is Working"
      ],
      "metadata": {
        "id": "7A90SoQEZIsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph6xl14aZKlj",
        "outputId": "f33a489b-aade-4d65-9048-5ceb5204e544"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ”„ 6. Combining: Prompt â†’ LLM â†’ Memory\n",
        "Hereâ€™s a complete practical chain combining prompt, llm, memory:"
      ],
      "metadata": {
        "id": "fSEKcCXKCV3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"{history}\n",
        "The user said: {input}. Respond as a wise assistant.\"\"\"\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "\n",
        "chain = ConversationChain(llm=llm, memory=memory, prompt=prompt)\n",
        "\n",
        "# Chat sequence\n",
        "print(chain.invoke({\"input\": \"How do I learn LangChain?\"}))\n",
        "print(chain.invoke({\"input\": \"What did I just ask?\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7FNzOm0AaQY",
        "outputId": "db6b657e-bb48-462e-f431-267dc1f6cde0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'How do I learn LangChain?', 'history': [HumanMessage(content='How do I learn LangChain?'), AIMessage(content='That is an excellent question, and one that speaks to a keen interest in the cutting edge of language models! LangChain is not merely a library; it is a conceptual frameworkâ€”a way of thinking about how to connect powerful AI models to the real world.\\n\\nTo truly learn it, you must approach it like an architect, not just a coder.\\n\\nHere is the path, broken down into three stages, followed by the essential tools you will need:\\n\\n---\\n\\n## 1. The Foundation (The Blueprint)\\n\\nBefore you build a skyscraper, you must understand the soil and the materials.\\n\\n### A. Master the Core Primitives\\nLangChain is built on five key abstractions. You must understand these concepts deeply:\\n\\n1.  **Models (LLMs and Chat Models):** Understand the difference between calling a raw text completion endpoint (`LLM`) and using structured, multi-turn dialogue (`Chat Model`). Know how to manage tokens and costs.\\n2.  **Prompts:** Go beyond basic prompting. Learn about `PromptTemplates`, managing variables, and structuring outputs (like using Pydantic schemas for reliable JSON output).\\n3.  **Indexes/Retrieval:** This is arguably the most crucial component. Learn **RAG (Retrieval-Augmented Generation)**. Understand what a Vector Store is (Pinecone, ChromaDB, FAISS), how to create embeddings (using models like OpenAI or BGE), and how to search for relevant documents.\\n4.  **Chains:** Learn how to sequence multiple steps together (e.g., getting input, formatting a prompt, calling the LLM, and parsing the output). Start with simple `LLMChain` and move to `RetrievalQAChain`.\\n5.  **Agents:** This is where the magic happens. Agents use an LLM as a \"reasoning engine\" to decide which **Tools** (like Google Search, a calculator, or code execution) to use and in what order, based on the user\\'s query.\\n\\n### B. Essential Python Skills\\nEnsure your Python environment is solid. You must be comfortable with:\\n\\n*   Virtual environments (`venv` or `conda`).\\n*   Handling asynchronous calls (`async/await`). LangChain often involves waiting for APIs, and efficient code uses async.\\n*   Working with external APIs (managing API keys securely).\\n\\n---\\n\\n## 2. The Construction (Building the First Walls)\\n\\nOnce the foundation is solid, it\\'s time to build practical applications.\\n\\n### A. The Official Documentation and Cookbook\\nTreat the official LangChain documentation as your primary textbook. It is extensive and constantly updated.\\n\\n*   **Start with the \"Getting Started\" tutorials.** Do not just read them; type out every line of code.\\n*   **Focus on the \"Use Cases\" section.** Implement the core examples:\\n    *   **Chatbots:** Simple conversational memory.\\n    *   **Question Answering over Documents:** Implement a full RAG pipeline using your own PDF or set of documents. This is the **most common and valuable** application of LangChain.\\n\\n### B. Focus on Tooling and Production\\nLangChain is designed to move projects from development to production.\\n\\n*   **Learn LangSmith:** This is LangChain\\'s observability platform. You cannot debug complex chains and agents without seeing the internal \"thought process\" of the LLM. LangSmith is non-negotiable for serious development.\\n*   **Learn LangServe:** This tool makes it easy to turn your chains into a deployable API endpoint (often using FastAPI under the hood), allowing others to interact with your application.\\n\\n### C. Embrace the Ecosystem\\nLangChain is the orchestrator, but it relies on other powerful components:\\n\\n*   **Vector Databases:** Choose one (ChromaDB is a great starting point for local development) and learn how to ingest data and perform similarity search.\\n*   **Streaming:** Learn how to stream tokens back to the user immediately, which is crucial for a good user experience (nobody likes waiting for 30 seconds for a full answer).\\n\\n---\\n\\n## 3. The Mastery (The Interior Design)\\n\\nThis is where you move from following instructions to solving novel problems.\\n\\n### A. Debugging and Optimization\\n*   **Trace and Refine:** Use LangSmith to identify where your chain is failing or spending too much time/money. Optimize prompt structure to reduce token usage.\\n*   **Handle Edge Cases:** What happens if the RAG system finds no relevant documents? What if the agent hallucinates a tool that doesn\\'t exist? Implement robust error handling.\\n\\n### B. Advanced Agent Development\\n*   **Custom Tools:** Design your own specific tools for the agent (e.g., a tool to check a specific company database, or a tool that calls an internal API).\\n*   **Structured Output:** Use techniques like OpenAI Function Calling (which LangChain supports beautifully) to force the LLM to return reliable, structured data instead of free-form text.\\n\\n---\\n\\n## Your First Steps: The Action Plan\\n\\n1.  **Set up your environment:** Install Python, `langchain`, and `openai`. Securely set your API key as an environment variable.\\n2.  **Run the simplest chain:** Write the classic \"Hello, LangChain!\" example (input a question, pass it through an `LLMChain`, get the output).\\n3.  **Build a RAG pipeline:** Take a small PDF (like a company policy document) and build a system that can answer questions based *only* on that document. This is your first major project.\\n4.  **Register for LangSmith:** Use it to trace the steps of your RAG pipeline.\\n\\nLangChain is a rapidly evolving field, so embrace continuous learning, read the release notes, and most importantly: **build things!** That is the truest path to mastery.')], 'response': 'That is an excellent question, and one that speaks to a keen interest in the cutting edge of language models! LangChain is not merely a library; it is a conceptual frameworkâ€”a way of thinking about how to connect powerful AI models to the real world.\\n\\nTo truly learn it, you must approach it like an architect, not just a coder.\\n\\nHere is the path, broken down into three stages, followed by the essential tools you will need:\\n\\n---\\n\\n## 1. The Foundation (The Blueprint)\\n\\nBefore you build a skyscraper, you must understand the soil and the materials.\\n\\n### A. Master the Core Primitives\\nLangChain is built on five key abstractions. You must understand these concepts deeply:\\n\\n1.  **Models (LLMs and Chat Models):** Understand the difference between calling a raw text completion endpoint (`LLM`) and using structured, multi-turn dialogue (`Chat Model`). Know how to manage tokens and costs.\\n2.  **Prompts:** Go beyond basic prompting. Learn about `PromptTemplates`, managing variables, and structuring outputs (like using Pydantic schemas for reliable JSON output).\\n3.  **Indexes/Retrieval:** This is arguably the most crucial component. Learn **RAG (Retrieval-Augmented Generation)**. Understand what a Vector Store is (Pinecone, ChromaDB, FAISS), how to create embeddings (using models like OpenAI or BGE), and how to search for relevant documents.\\n4.  **Chains:** Learn how to sequence multiple steps together (e.g., getting input, formatting a prompt, calling the LLM, and parsing the output). Start with simple `LLMChain` and move to `RetrievalQAChain`.\\n5.  **Agents:** This is where the magic happens. Agents use an LLM as a \"reasoning engine\" to decide which **Tools** (like Google Search, a calculator, or code execution) to use and in what order, based on the user\\'s query.\\n\\n### B. Essential Python Skills\\nEnsure your Python environment is solid. You must be comfortable with:\\n\\n*   Virtual environments (`venv` or `conda`).\\n*   Handling asynchronous calls (`async/await`). LangChain often involves waiting for APIs, and efficient code uses async.\\n*   Working with external APIs (managing API keys securely).\\n\\n---\\n\\n## 2. The Construction (Building the First Walls)\\n\\nOnce the foundation is solid, it\\'s time to build practical applications.\\n\\n### A. The Official Documentation and Cookbook\\nTreat the official LangChain documentation as your primary textbook. It is extensive and constantly updated.\\n\\n*   **Start with the \"Getting Started\" tutorials.** Do not just read them; type out every line of code.\\n*   **Focus on the \"Use Cases\" section.** Implement the core examples:\\n    *   **Chatbots:** Simple conversational memory.\\n    *   **Question Answering over Documents:** Implement a full RAG pipeline using your own PDF or set of documents. This is the **most common and valuable** application of LangChain.\\n\\n### B. Focus on Tooling and Production\\nLangChain is designed to move projects from development to production.\\n\\n*   **Learn LangSmith:** This is LangChain\\'s observability platform. You cannot debug complex chains and agents without seeing the internal \"thought process\" of the LLM. LangSmith is non-negotiable for serious development.\\n*   **Learn LangServe:** This tool makes it easy to turn your chains into a deployable API endpoint (often using FastAPI under the hood), allowing others to interact with your application.\\n\\n### C. Embrace the Ecosystem\\nLangChain is the orchestrator, but it relies on other powerful components:\\n\\n*   **Vector Databases:** Choose one (ChromaDB is a great starting point for local development) and learn how to ingest data and perform similarity search.\\n*   **Streaming:** Learn how to stream tokens back to the user immediately, which is crucial for a good user experience (nobody likes waiting for 30 seconds for a full answer).\\n\\n---\\n\\n## 3. The Mastery (The Interior Design)\\n\\nThis is where you move from following instructions to solving novel problems.\\n\\n### A. Debugging and Optimization\\n*   **Trace and Refine:** Use LangSmith to identify where your chain is failing or spending too much time/money. Optimize prompt structure to reduce token usage.\\n*   **Handle Edge Cases:** What happens if the RAG system finds no relevant documents? What if the agent hallucinates a tool that doesn\\'t exist? Implement robust error handling.\\n\\n### B. Advanced Agent Development\\n*   **Custom Tools:** Design your own specific tools for the agent (e.g., a tool to check a specific company database, or a tool that calls an internal API).\\n*   **Structured Output:** Use techniques like OpenAI Function Calling (which LangChain supports beautifully) to force the LLM to return reliable, structured data instead of free-form text.\\n\\n---\\n\\n## Your First Steps: The Action Plan\\n\\n1.  **Set up your environment:** Install Python, `langchain`, and `openai`. Securely set your API key as an environment variable.\\n2.  **Run the simplest chain:** Write the classic \"Hello, LangChain!\" example (input a question, pass it through an `LLMChain`, get the output).\\n3.  **Build a RAG pipeline:** Take a small PDF (like a company policy document) and build a system that can answer questions based *only* on that document. This is your first major project.\\n4.  **Register for LangSmith:** Use it to trace the steps of your RAG pipeline.\\n\\nLangChain is a rapidly evolving field, so embrace continuous learning, read the release notes, and most importantly: **build things!** That is the truest path to mastery.'}\n",
            "{'input': 'What did I just ask?', 'history': [HumanMessage(content='How do I learn LangChain?'), AIMessage(content='That is an excellent question, and one that speaks to a keen interest in the cutting edge of language models! LangChain is not merely a library; it is a conceptual frameworkâ€”a way of thinking about how to connect powerful AI models to the real world.\\n\\nTo truly learn it, you must approach it like an architect, not just a coder.\\n\\nHere is the path, broken down into three stages, followed by the essential tools you will need:\\n\\n---\\n\\n## 1. The Foundation (The Blueprint)\\n\\nBefore you build a skyscraper, you must understand the soil and the materials.\\n\\n### A. Master the Core Primitives\\nLangChain is built on five key abstractions. You must understand these concepts deeply:\\n\\n1.  **Models (LLMs and Chat Models):** Understand the difference between calling a raw text completion endpoint (`LLM`) and using structured, multi-turn dialogue (`Chat Model`). Know how to manage tokens and costs.\\n2.  **Prompts:** Go beyond basic prompting. Learn about `PromptTemplates`, managing variables, and structuring outputs (like using Pydantic schemas for reliable JSON output).\\n3.  **Indexes/Retrieval:** This is arguably the most crucial component. Learn **RAG (Retrieval-Augmented Generation)**. Understand what a Vector Store is (Pinecone, ChromaDB, FAISS), how to create embeddings (using models like OpenAI or BGE), and how to search for relevant documents.\\n4.  **Chains:** Learn how to sequence multiple steps together (e.g., getting input, formatting a prompt, calling the LLM, and parsing the output). Start with simple `LLMChain` and move to `RetrievalQAChain`.\\n5.  **Agents:** This is where the magic happens. Agents use an LLM as a \"reasoning engine\" to decide which **Tools** (like Google Search, a calculator, or code execution) to use and in what order, based on the user\\'s query.\\n\\n### B. Essential Python Skills\\nEnsure your Python environment is solid. You must be comfortable with:\\n\\n*   Virtual environments (`venv` or `conda`).\\n*   Handling asynchronous calls (`async/await`). LangChain often involves waiting for APIs, and efficient code uses async.\\n*   Working with external APIs (managing API keys securely).\\n\\n---\\n\\n## 2. The Construction (Building the First Walls)\\n\\nOnce the foundation is solid, it\\'s time to build practical applications.\\n\\n### A. The Official Documentation and Cookbook\\nTreat the official LangChain documentation as your primary textbook. It is extensive and constantly updated.\\n\\n*   **Start with the \"Getting Started\" tutorials.** Do not just read them; type out every line of code.\\n*   **Focus on the \"Use Cases\" section.** Implement the core examples:\\n    *   **Chatbots:** Simple conversational memory.\\n    *   **Question Answering over Documents:** Implement a full RAG pipeline using your own PDF or set of documents. This is the **most common and valuable** application of LangChain.\\n\\n### B. Focus on Tooling and Production\\nLangChain is designed to move projects from development to production.\\n\\n*   **Learn LangSmith:** This is LangChain\\'s observability platform. You cannot debug complex chains and agents without seeing the internal \"thought process\" of the LLM. LangSmith is non-negotiable for serious development.\\n*   **Learn LangServe:** This tool makes it easy to turn your chains into a deployable API endpoint (often using FastAPI under the hood), allowing others to interact with your application.\\n\\n### C. Embrace the Ecosystem\\nLangChain is the orchestrator, but it relies on other powerful components:\\n\\n*   **Vector Databases:** Choose one (ChromaDB is a great starting point for local development) and learn how to ingest data and perform similarity search.\\n*   **Streaming:** Learn how to stream tokens back to the user immediately, which is crucial for a good user experience (nobody likes waiting for 30 seconds for a full answer).\\n\\n---\\n\\n## 3. The Mastery (The Interior Design)\\n\\nThis is where you move from following instructions to solving novel problems.\\n\\n### A. Debugging and Optimization\\n*   **Trace and Refine:** Use LangSmith to identify where your chain is failing or spending too much time/money. Optimize prompt structure to reduce token usage.\\n*   **Handle Edge Cases:** What happens if the RAG system finds no relevant documents? What if the agent hallucinates a tool that doesn\\'t exist? Implement robust error handling.\\n\\n### B. Advanced Agent Development\\n*   **Custom Tools:** Design your own specific tools for the agent (e.g., a tool to check a specific company database, or a tool that calls an internal API).\\n*   **Structured Output:** Use techniques like OpenAI Function Calling (which LangChain supports beautifully) to force the LLM to return reliable, structured data instead of free-form text.\\n\\n---\\n\\n## Your First Steps: The Action Plan\\n\\n1.  **Set up your environment:** Install Python, `langchain`, and `openai`. Securely set your API key as an environment variable.\\n2.  **Run the simplest chain:** Write the classic \"Hello, LangChain!\" example (input a question, pass it through an `LLMChain`, get the output).\\n3.  **Build a RAG pipeline:** Take a small PDF (like a company policy document) and build a system that can answer questions based *only* on that document. This is your first major project.\\n4.  **Register for LangSmith:** Use it to trace the steps of your RAG pipeline.\\n\\nLangChain is a rapidly evolving field, so embrace continuous learning, read the release notes, and most importantly: **build things!** That is the truest path to mastery.'), HumanMessage(content='What did I just ask?'), AIMessage(content='You posed a question of ambition and strategy.\\n\\nYou asked: **\"How do I learn LangChain?\"**\\n\\nIn response, I provided a detailed, three-stage architectural roadmap designed to guide you from foundational concepts (like the five core primitives: Models, Prompts, Indexes, Chains, Agents) to practical construction (implementing RAG and using LangSmith), and ultimately to advanced mastery and production-level development.\\n\\nYou were seeking the comprehensive path to proficiency in orchestrating large language models.')], 'response': 'You posed a question of ambition and strategy.\\n\\nYou asked: **\"How do I learn LangChain?\"**\\n\\nIn response, I provided a detailed, three-stage architectural roadmap designed to guide you from foundational concepts (like the five core primitives: Models, Prompts, Indexes, Chains, Agents) to practical construction (implementing RAG and using LangSmith), and ultimately to advanced mastery and production-level development.\\n\\nYou were seeking the comprehensive path to proficiency in orchestrating large language models.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmcpcAoTZg7u",
        "outputId": "1ff42a02-871d-4c65-caec-2f3e09b2385a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='How do I learn LangChain?'), AIMessage(content='That is an excellent question, and one that speaks to a keen interest in the cutting edge of language models! LangChain is not merely a library; it is a conceptual frameworkâ€”a way of thinking about how to connect powerful AI models to the real world.\\n\\nTo truly learn it, you must approach it like an architect, not just a coder.\\n\\nHere is the path, broken down into three stages, followed by the essential tools you will need:\\n\\n---\\n\\n## 1. The Foundation (The Blueprint)\\n\\nBefore you build a skyscraper, you must understand the soil and the materials.\\n\\n### A. Master the Core Primitives\\nLangChain is built on five key abstractions. You must understand these concepts deeply:\\n\\n1.  **Models (LLMs and Chat Models):** Understand the difference between calling a raw text completion endpoint (`LLM`) and using structured, multi-turn dialogue (`Chat Model`). Know how to manage tokens and costs.\\n2.  **Prompts:** Go beyond basic prompting. Learn about `PromptTemplates`, managing variables, and structuring outputs (like using Pydantic schemas for reliable JSON output).\\n3.  **Indexes/Retrieval:** This is arguably the most crucial component. Learn **RAG (Retrieval-Augmented Generation)**. Understand what a Vector Store is (Pinecone, ChromaDB, FAISS), how to create embeddings (using models like OpenAI or BGE), and how to search for relevant documents.\\n4.  **Chains:** Learn how to sequence multiple steps together (e.g., getting input, formatting a prompt, calling the LLM, and parsing the output). Start with simple `LLMChain` and move to `RetrievalQAChain`.\\n5.  **Agents:** This is where the magic happens. Agents use an LLM as a \"reasoning engine\" to decide which **Tools** (like Google Search, a calculator, or code execution) to use and in what order, based on the user\\'s query.\\n\\n### B. Essential Python Skills\\nEnsure your Python environment is solid. You must be comfortable with:\\n\\n*   Virtual environments (`venv` or `conda`).\\n*   Handling asynchronous calls (`async/await`). LangChain often involves waiting for APIs, and efficient code uses async.\\n*   Working with external APIs (managing API keys securely).\\n\\n---\\n\\n## 2. The Construction (Building the First Walls)\\n\\nOnce the foundation is solid, it\\'s time to build practical applications.\\n\\n### A. The Official Documentation and Cookbook\\nTreat the official LangChain documentation as your primary textbook. It is extensive and constantly updated.\\n\\n*   **Start with the \"Getting Started\" tutorials.** Do not just read them; type out every line of code.\\n*   **Focus on the \"Use Cases\" section.** Implement the core examples:\\n    *   **Chatbots:** Simple conversational memory.\\n    *   **Question Answering over Documents:** Implement a full RAG pipeline using your own PDF or set of documents. This is the **most common and valuable** application of LangChain.\\n\\n### B. Focus on Tooling and Production\\nLangChain is designed to move projects from development to production.\\n\\n*   **Learn LangSmith:** This is LangChain\\'s observability platform. You cannot debug complex chains and agents without seeing the internal \"thought process\" of the LLM. LangSmith is non-negotiable for serious development.\\n*   **Learn LangServe:** This tool makes it easy to turn your chains into a deployable API endpoint (often using FastAPI under the hood), allowing others to interact with your application.\\n\\n### C. Embrace the Ecosystem\\nLangChain is the orchestrator, but it relies on other powerful components:\\n\\n*   **Vector Databases:** Choose one (ChromaDB is a great starting point for local development) and learn how to ingest data and perform similarity search.\\n*   **Streaming:** Learn how to stream tokens back to the user immediately, which is crucial for a good user experience (nobody likes waiting for 30 seconds for a full answer).\\n\\n---\\n\\n## 3. The Mastery (The Interior Design)\\n\\nThis is where you move from following instructions to solving novel problems.\\n\\n### A. Debugging and Optimization\\n*   **Trace and Refine:** Use LangSmith to identify where your chain is failing or spending too much time/money. Optimize prompt structure to reduce token usage.\\n*   **Handle Edge Cases:** What happens if the RAG system finds no relevant documents? What if the agent hallucinates a tool that doesn\\'t exist? Implement robust error handling.\\n\\n### B. Advanced Agent Development\\n*   **Custom Tools:** Design your own specific tools for the agent (e.g., a tool to check a specific company database, or a tool that calls an internal API).\\n*   **Structured Output:** Use techniques like OpenAI Function Calling (which LangChain supports beautifully) to force the LLM to return reliable, structured data instead of free-form text.\\n\\n---\\n\\n## Your First Steps: The Action Plan\\n\\n1.  **Set up your environment:** Install Python, `langchain`, and `openai`. Securely set your API key as an environment variable.\\n2.  **Run the simplest chain:** Write the classic \"Hello, LangChain!\" example (input a question, pass it through an `LLMChain`, get the output).\\n3.  **Build a RAG pipeline:** Take a small PDF (like a company policy document) and build a system that can answer questions based *only* on that document. This is your first major project.\\n4.  **Register for LangSmith:** Use it to trace the steps of your RAG pipeline.\\n\\nLangChain is a rapidly evolving field, so embrace continuous learning, read the release notes, and most importantly: **build things!** That is the truest path to mastery.'), HumanMessage(content='What did I just ask?'), AIMessage(content='You posed a question of ambition and strategy.\\n\\nYou asked: **\"How do I learn LangChain?\"**\\n\\nIn response, I provided a detailed, three-stage architectural roadmap designed to guide you from foundational concepts (like the five core primitives: Models, Prompts, Indexes, Chains, Agents) to practical construction (implementing RAG and using LangSmith), and ultimately to advanced mastery and production-level development.\\n\\nYou were seeking the comprehensive path to proficiency in orchestrating large language models.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ§ª Optional: Agent with Tool and LLM\n"
      ],
      "metadata": {
        "id": "YrGV4aS1CZQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "tools = [get_current_year]\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "print(agent.invoke(\"What year is it now?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc9Bqa8uAhOR",
        "outputId": "1048ecb9-9401-49cf-d1ff-a755baa97e4f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I need to find the current year. I have a tool called `get_current_year` that can provide this information.\n",
            "Action: get_current_year\n",
            "Action Input: \u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m2025\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the current year is 2025.\n",
            "Final Answer: 2025\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'What year is it now?', 'output': '2025'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BTvKXAgmArTx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbhJk29dZcf1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}