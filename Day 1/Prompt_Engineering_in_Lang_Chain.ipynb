{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Prompt Engineering in Lang Chain"
      ],
      "metadata": {
        "id": "WPKI6B9jVzHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Common Setup (One-Time)"
      ],
      "metadata": {
        "id": "Xf5PDaiDVwea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L49PL0rZSKBp",
        "outputId": "248d8880-1b32-44cd-945b-8b60e052aa7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.5)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.1)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.53.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.54.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.41.5)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (4.12.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (2.43.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.4.56)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain-google-genai pydantic\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Set API key as environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD45v3dg7V5J0J0sK_pyhqzuksZlYlqhIA\"\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-flash-latest\",\n",
        "    temperature=0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "xlcOg7MLSLPJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical 1: Few-Shot Prompting for Summarization\n",
        "\n",
        "Scenario: Executive-level summarization of technical/business updates."
      ],
      "metadata": {
        "id": "qrDqwcSPV6Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import prompt utilities required for few-shot prompting\n",
        "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "\n",
        "# Define few-shot examples\n",
        "# Each example demonstrates how an input text should be summarized\n",
        "examples = [\n",
        "    {\n",
        "        \"input\": \"The system experienced latency due to unoptimized queries.\",\n",
        "        \"output\": \"System performance degraded because database queries were inefficient.\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Customer churn increased after recent UI changes.\",\n",
        "        \"output\": \"Recent UI changes negatively affected customer retention.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create a prompt template for formatting each example\n",
        "# This controls how each example is presented to the LLM\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Text: {input}\\nSummary: {output}\\n\"\n",
        ")\n",
        "\n",
        "# Create the few-shot prompt template\n",
        "# - prefix: sets the role and expectations of the LLM\n",
        "# - examples: provides learning examples (few-shot)\n",
        "# - suffix: defines where the new input will be injected\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"You are a senior business analyst. Provide a clear and concise summary.\",\n",
        "    suffix=\"Text: {text}\\nSummary:\",\n",
        "    input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "# Invoke the LLM with a new input text\n",
        "# The model will infer the summarization style from the examples\n",
        "response = llm.invoke(\n",
        "    few_shot_prompt.format(\n",
        "        text=(\n",
        "            \"After the new software release, \"\n",
        "            \"error rates dropped, but support tickets increased \"\n",
        "            \"due to insufficient user onboarding.\"\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "# Print the generated summary from the LLM response\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB5tE0EUSTpn",
        "outputId": "c6b8d527-f02e-4d0b-b984-5b503230f832"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The software release reduced errors, but inadequate onboarding drove up support ticket volume.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical 2: Structured Output Summarization (JSON Format)\n",
        "\n",
        "Scenario: Convert meeting notes into structured, actionable insights."
      ],
      "metadata": {
        "id": "vJ4YZYemV9mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import BaseModel and Field from Pydantic for defining structured data schemas\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Import LangChain utilities for structured output parsing and prompt templating\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Define a Pydantic model to enforce structured output from the LLM\n",
        "# This model represents the expected meeting summary format\n",
        "class MeetingSummary(BaseModel):\n",
        "    # Main topic discussed in the meeting\n",
        "    topic: str = Field(description=\"Main meeting topic\")\n",
        "\n",
        "    # List of key discussion points from the meeting\n",
        "    key_points: list[str] = Field(description=\"Key discussion points\")\n",
        "\n",
        "    # List of action items agreed upon during the meeting\n",
        "    action_items: list[str] = Field(description=\"Action items decided\")\n",
        "\n",
        "# Create a Pydantic output parser using the MeetingSummary schema\n",
        "# This ensures the LLM output follows the defined JSON structure\n",
        "parser = PydanticOutputParser(pydantic_object=MeetingSummary)\n",
        "\n",
        "# Define a prompt template for summarizing meeting notes\n",
        "# The format instructions guide the LLM to return valid structured JSON\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Summarize the following meeting notes into structured JSON.\n",
        "{format_instructions}\n",
        "\n",
        "Meeting Notes:\n",
        "{text}\n",
        "\"\"\",\n",
        "    # Variable part of the prompt (meeting notes text)\n",
        "    input_variables=[\"text\"],\n",
        "\n",
        "    # Static instructions injected into the prompt for output formatting\n",
        "    partial_variables={\n",
        "        \"format_instructions\": parser.get_format_instructions()\n",
        "    },\n",
        ")\n",
        "\n",
        "# Invoke the LLM with the formatted prompt\n",
        "response = llm.invoke(\n",
        "    prompt.format(\n",
        "        text=(\n",
        "            \"The team discussed high cloud costs, agreed to optimize storage usage, \"\n",
        "            \"and assigned DevOps to implement monitoring in the next sprint.\"\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "# Parse the LLM response into a strongly-typed Pydantic object\n",
        "# This will raise an error if the output does not match the schema\n",
        "structured_summary = parser.parse(response.content)\n",
        "\n",
        "# Print the structured meeting summary\n",
        "print(structured_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKmnhk_YSUrz",
        "outputId": "9a6b5c44-4839-47c7-e5ee-eb7d80d94732"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic='High Cloud Cost Review and Optimization' key_points=['Discussion on current high cloud costs.', 'Agreement reached to prioritize optimization of storage usage.'] action_items=['DevOps team assigned to implement monitoring during the next sprint.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical 3: Multi-Scenario Few-Shot Summarization (Domain-Based)\n",
        "\n",
        "Scenario: Accurate summaries across different domains."
      ],
      "metadata": {
        "id": "W_AT47JhWAU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ChatPromptTemplate to create structured, multi-message prompts\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define a few-shot prompt using system and human messages\n",
        "# This helps the LLM learn how to summarize text based on different domains\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "\n",
        "    # System message sets the overall behavior of the LLM\n",
        "    (\"system\", \"You are an expert summarizer. Adapt your summary based on the domain.\"),\n",
        "\n",
        "    # Few-shot example 1: News domain\n",
        "    # Shows how news content should be summarized\n",
        "    (\"human\",\n",
        "     \"Domain: News\\n\"\n",
        "     \"Text: The central bank raised interest rates.\\n\"\n",
        "     \"Summary: Interest rates were increased to control inflation.\"),\n",
        "\n",
        "    # Few-shot example 2: Legal domain\n",
        "    # Demonstrates formal and precise legal summarization\n",
        "    (\"human\",\n",
        "     \"Domain: Legal\\n\"\n",
        "     \"Text: The court dismissed the appeal due to lack of evidence.\\n\"\n",
        "     \"Summary: The appeal was rejected for insufficient evidence.\"),\n",
        "\n",
        "    # Few-shot example 3: Medical domain\n",
        "    # Emphasizes clinical clarity in medical summaries\n",
        "    (\"human\",\n",
        "     \"Domain: Medical\\n\"\n",
        "     \"Text: Patient oxygen levels improved after treatment.\\n\"\n",
        "     \"Summary: Treatment led to improved oxygen saturation.\"),\n",
        "\n",
        "    # Final template message\n",
        "    # Placeholders {domain} and {text} will be filled dynamically at runtime\n",
        "    (\"human\",\n",
        "     \"Domain: {domain}\\n\"\n",
        "     \"Text: {text}\\n\"\n",
        "     \"Summary:\")\n",
        "])\n",
        "\n",
        "# Invoke the LLM with formatted messages\n",
        "# The model will generate a domain-aware summary for the given input\n",
        "response = llm.invoke(\n",
        "    prompt.format_messages(\n",
        "        domain=\"Technology\",  # Target domain for summarization\n",
        "        text=\"The company launched a new AI model that improves response time while reducing infrastructure costs.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Print only the generated summary content from the LLM response\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHAmEBJ_SW1H",
        "outputId": "8a065d8e-ea8b-4383-a36a-e0b749fa651f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'type': 'text', 'text': 'New AI model deployment yields lower latency and decreased infrastructure expenditure.', 'extras': {'signature': 'CtULAXLI2nwdPpWAIPE2T28/9EsqjhwoQEkZ+3ado1mktIJFH+esqJNbOz7R2mWZrI7rhzmqCdF7njXmWFE9YZv+FzIRF6nQGmHOWCiidjT+I0iXgdfVPiAGXwDxHhlsONYOlUq+k01uQ7e23cxb7jYxvRDMzIF2+mpRLDgMwEpt13lRv8c7FKi+MW6ynDr8rOKt5OmRGaFQ3o1PsoSS+XmNoh8LnCS0Et5bqyFPmRfQpxBdfYAV27DMeDukkQJNTTaP6h/9v2eaOr6AROSpw8cTaQz+Up2BJSYppXQjePqewGfEy9h4wupkkRYqDjLoL1vYZLrBAIpqAlaDwa+F4Jkysd0OPJm/JmyG3o2uTHsFmVANHprQjLb6XxBX7xzIuWgDGXwUZ2YPXw/HMJl0SgOzsWsqostNPiH2yIEXOX63PTT9rFA8XpTzKD8XkLcGxw23WNwd1kFtD+U6qnLjcYnT0vo40l7mOlk9+E3ukhMbWBDEcM7etQscXuFfpW+Wd9hAnL2Ka83k+NPuNb5ZPq5PTi4FgRasui3+37MAyCm4arr1WdUztfUWrj+QJ1V3csGG/GNyMx9Srq4IyI0mJwGj7VNx8DFju0U13Gf/5/WyqOZwvhexJH5sChDN2hzIVVKR2cejupg8M8127HjhBTKPrhVxftrFaer9zbfc/l59PAtP5pDKqLy0CKQkGxU78pILHFOyBpYdtQ9IQLCJDyAPl0sc3FeLIeJ4fD7o7VIHygd5iJAFVo48CHVTcem25AHJdc9s4OYwZAPYRXTDZ65eI0G9TWfK04IjEnbNXt8LqiEsX/ZAfrTV4QhYh3SyCi7o4al4pRG8azBJHbEOmBfsGCAHeBHMtTARp77qK0NHiYTZHT/PhEV6m8QiGULN2Ev6l4dznBQv5ltIU+Ja9LTdeUGkQKpJdpsUDEAYmLOpXvksyY51GuWAbvM4889vTdovOybz0MAKSc3/uGx4vpaNvkml8XQB4x/UGfFh3W9472ih2wDK8scARvcC4cNJXQCJVZDaa66Zz5+12CK0wzZKSigMHAvw/ChRUgDJvf0zra65RKZInrM1uMLvuYIph3FbMm6Zdhot0WbyAFqk51wKEZsT6BdQlrkqJKJ9Sum/m2WGMsz5VZg/RniY4lgaxVqJu/uNXwQpTrsOELJFAlqpn0WWRNqFlDa3+321JOW3iS59Ntsd1yzO1ZdH17LkmJz476MmMhZyUFPtlCraEW0xh/vXWzybF4jfipRngw38Ex9qK0JAQNxofb+wG8KZZSE93Z1xYBwO9irY0yhDDy49LLBJl/emLKmWtseJW3lMPVKgISiDWCBashXaQGH9z+FphDJIT8NkAvwIMiQgh7KPRI9Op4JGK10w9KGj6He9s8hGOpWwXJL1I9+OGjNRmDkiJEMs63qePCij349bEmFo99kcEbf3QXyzauawLO1uM7YyXWklTzMUpLJF/+U/GmffXcBUtXTaTBIrWiGcWG8wr0wPkVf/7scJgKeZjmgMbz48MXE81lYp0suRJCyg5xiE0ETvFV+cMsaIeBzxnqkvFrnD6zlCQB0vgJjAjREw/7HvoKU1gcB9mad8d7FFkp4ZUa1CfNYyvxNjU309TM+ilA0K272bIT0InWRhxGw9vDRFW6Q/HrgI4suVYi7lBgOsacE7aKDnY9hmbpLJoie4VVGx8TJUm1wIN6/kR2wj06Howjm0YFLW8jqY4mVluqn/BV+y6dwoqpO+uMLXGhZgXVyTfqi4wZnm+DW1gMo9NY51mG9L0fBfuueEka7IRerUf2qCgZz8GpWnJF8Y6Bj5MjBsPPzBT/kFxkkY44RRO7ZmeSPRsGe/0BCaJ89dRUM67oPlUVE2lpSzdFISClf7JVpt8cLTkhuZmBYNOJAgbg+Ou6pg2qMuPm7djNCnuwMOUfbFa3yiO7mbvMgEp0ADGE6BbnAuOXW3qlv+EpUfa+lsXGCVeFX7hMiLxP94t77gBhXfzqw='}}]\n"
          ]
        }
      ]
    }
  ]
}